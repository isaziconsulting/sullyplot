% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sullyplot_openai_continue_chat.R
\name{sullyplot_openai_continue_chat}
\alias{sullyplot_openai_continue_chat}
\title{Make a continue chat request with openai chat completion endpoint and track token usage.}
\usage{
sullyplot_openai_continue_chat(
  chat_messages,
  system_message = NULL,
  model_name = "gpt-4",
  max_tokens = 16384,
  options = list()
)
}
\arguments{
\item{chat_messages}{The input data frame of chat messages (see openai api docs for format).}

\item{system_message}{Optional system prompt which will be added to chat messages.}

\item{model_name}{The name of the model to use. Default 'gpt-4'.}

\item{max_tokens}{The maximum number of tokens in the response. Default is 150.}

\item{options}{Additional options such as temperature}
}
\value{
The response message as well as the amount of prompt and completion tokens used.
}
\description{
This function uses the openai api chat completions endpoint to continue a chat from a series of chat messages and optionally a system prompt, also returns usage statistics.
}
