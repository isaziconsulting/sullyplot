% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sullyplot_azure_continue_chat.R
\name{sullyplot_azure_continue_chat}
\alias{sullyplot_azure_continue_chat}
\title{Make a continue chat request with azure openai chat completion endpoint and track token usage.}
\usage{
sullyplot_azure_continue_chat(
  chat_messages,
  system_message = NULL,
  deployment_id = "gpt-4",
  api_version = "2023-05-15",
  max_tokens = 16384,
  options = list()
)
}
\arguments{
\item{chat_messages}{The input data frame of chat messages (see openai api docs for format).}

\item{system_message}{Optional system prompt which will be added to chat messages.}

\item{deployment_id}{The azure deployment id for the model you want to use. Default is 'gpt-4'.}

\item{api_version}{The azure openai api version. Default is '2023-05-15'.}

\item{max_tokens}{The maximum number of tokens in the response. Default is 150.}

\item{options}{Additional options such as temperature}
}
\value{
The response message as well as the amount of prompt and completion tokens used.
}
\description{
This function uses the azure openai api chat completions endpoint to continue a chat from a series of chat messages and optionally a system prompt, also returns usage statistics.
If azure openai is not configured, it will default to using the openai api using `sullyplot_openai_continue_chat`.
}
